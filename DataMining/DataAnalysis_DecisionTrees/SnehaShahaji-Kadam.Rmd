---
title: "CS 422"
output: 
  html_notebook :
    toc: yes
    toc_float: yes
author: Sneha Shahaji Kadam
editor_options: 
  chunk_output_type: inline
---

### Part 2.1(a)
```{r}
rm(list=ls())
df <- read.csv("hotel_bookings.csv", header=T)

library(plyr)
hotel_freq <- count(df,'hotel')
cat(paste0("Dataset has ",hotel_freq[2,2]," observations for Hotel type H1(Resort Hotel) and ",hotel_freq[1,2]," observations for Hotel type H2(City Hotel)."))
```

### Part 2.1(b)
```{r}
cat(paste0("Number of guests who canceled reservation: ", sum(df$is_canceled)),"\n")

cat(paste0("Number of guests who did not cancel reservation: ", sum(df$is_canceled==0)))
```

### Part 2.1 (c)
```{r}
customer_reservation <-count(df,'customer_type')
max_row <- which.max(customer_reservation[,2])

cat(paste0("Customer type with the most reservations is ",customer_reservation[max_row,1],", with " , customer_reservation[max_row,2], " reservations"))
```

### Part 2.1(d)
```{r}
customer_parkings <- count(df, c("customer_type", "required_car_parking_spaces"))
max_row1 <- which.max(customer_parkings[,2])

cat(paste0(customer_parkings[max_row1,3]," customers required the most number of parking spaces( ",customer_parkings[max_row1,2]),").")
```

### Part 2.1(e)
```{r}
min_row1 <- which.min(customer_parkings[,2])
min_values_rows <- ddply(subset(df, required_car_parking_spaces==customer_parkings[min_row1,2]),.(customer_type),nrow)

cat(paste0(sum(min_values_rows$V1)," customers required the least number of parking spaces( ",customer_parkings[min_row1,2]),").")
```

### Part 2.1(f)
```{r}
preference_matched <- sum(as.character(df$reserved_room_type) == as.character(df$assigned_room_type))

preference_matched_percentage <- round((preference_matched*100/119390),digits=2)

cat(paste0(preference_matched_percentage," %" ," of the people who expressed a room preference during reservation got the room during check-in."))
```

### Part 2.1(g)
```{r}
city_hotel_country_count <- ddply(subset(df, hotel=="City Hotel"),.(country),nrow)
resort_hotel_country_count <- ddply(subset(df, hotel=="Resort Hotel"),.(country),nrow)
resort_hotel_country_count_new <- resort_hotel_country_count[!(resort_hotel_country_count$country=="NULL"),]

sort1 <- tail(city_hotel_country_count[order(city_hotel_country_count[,2]),],10)
sort2 <- tail(resort_hotel_country_count_new[order(resort_hotel_country_count_new[,2]),],10)

barplot(sort1[,2],col=rainbow(10),names=sort1[,1],main="Top 10 countries of origin for City hotel")
barplot(sort2[,2],col=rainbow(10),names=sort2[,1],main="Top 10 countries of origin for Resort hotel")
```

### Part 2.1(h)(i)
```{r}
cat(paste0("Most visitors to either type of the hotels arrive from country : ", sort1[10,1]))
```

### Part 2.1(h)(ii)
```{r}
#Hotel Bookings Dataset has maximum bookings from country PRT.
```

### Part 2.2
```{r}
library(rpart)
library(caret)
library(rpart.plot)

df$is_canceled <- as.factor(df$is_canceled)

df$country <- as.integer(df$country)
df$reservation_status_date <- as.integer(df$reservation_status_date)
df$agent <- as.integer(df$agent)

set.seed(1122)
index <- sample(1:nrow(df), 0.90*dim(df)[1])
train.df <- df[index,]
test.df <- df[-index,]
```
### Part 2.2(a)
```{r}
model <- rpart(is_canceled~lead_time+arrival_date_year+previous_cancellations+total_of_special_requests+market_segment+deposit_type+country+reservation_status_date+agent, method="class", data=train.df)
```

### Part 2.2 (a)(i)
```{r}
rpart.plot(model, extra=104, fallen.leaves=T, type=4, main="Is canceled Model")
```

### Part 2.2 (a)(ii)
```{r}
#List of important predictor variables(9) are as follows:
#lead_time
#arrival_date_year
#previous_cancellations
#total_of_special_requests
#market_segment
#deposit_type
#country
#reservation_status_date
#agent
```

### part 2.2 (a)(iii)
```{r}
pred <- predict(model, test.df, type="class")
pred.prob <- predict(model, test.df, type="prob")
c <- confusionMatrix(pred, as.factor(test.df$is_canceled))

cat(paste0("Accuracy is ",round(c$overall["Accuracy"], 4),"\n"))
cat(paste0("Error is ",round(1-c$overall["Accuracy"],4),"\n"))
cat(paste0("Balanced-Accuracy is ",round(c$byClass["Balanced Accuracy"],4),"\n"))
cat(paste0("Specificity is ",round(c$byClass["Specificity"],4),"\n"))
cat(paste0("Sensitivity is ",round(c$byClass["Sensitivity"],4),"\n"))
```

### Part 2.2 (a)(iv)
```{r}
library(ROCR)
rocr <- pred.prob[,2]
f.pred <- prediction(rocr, test.df$is_canceled)
plot(performance(f.pred, "tpr", "fpr"), colorize=T, lwd=3)
abline(0,1)
```

### Part 2.2 (a)(v)
```{r}
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for ROC curve is ", round(auc@y.values[[1]], 3)))
```

### Part 2.2 (b)
```{r}
printcp(model)
plotcp(model)

# Part 2.2 (b) (i) As xerror is continuously decreasing, tree does not reuire any pruning.
```

### Part 2.2 (c)
```{r}
library(randomForest)
rm(model, pred)

i <- 1
j <- 1
k <- 1
ntree <-  c(250,500,750)
mtry <- c(4,6,8)

for (j in 1:3)
{
  for (k in 1:3)
  {
    model <- randomForest(is_canceled~lead_time+arrival_date_year+previous_cancellations+total_of_special_requests+market_segment+deposit_type+country+reservation_status_date+agent, ntree= ntree[j], mtry=mtry[k], data=train.df)
    pred <- predict(model, test.df, type="class")
    conf_mat <- confusionMatrix(pred, as.factor(test.df$is_canceled))
    cat(paste0("RandomForest model ",i," with ntree: ",ntree[j]," and mtry: ",mtry[k],"\n"))
    print(model)
    print(conf_mat)
    k <- k+1
    i <- i+1
    }
  j <- j+1
}
```

### Part 2.2 (c)(i)
```{r}
#Random forest model with ntree=250, mtry=6 is best as it shows the maximum balanced accuracy(0.9003), sensitivity(0.9483) and specificity(0.8527). 
```

### Part 2.2 (c)(ii)
```{r}
#Random forest model with ntree=500, mtry=6 and ntree=750, mtry=6 is best as it shows the lowest OOB error(8.71%).
```

### Part 2.2 (c)(iii)
```{r}
# Best models from (i) and (ii) are different.
# OOB error decreases With increasing number of trees as we have more patterns.
# Balanced accuracy is mean of sensitivity and specificity. This model has  higher specificity, indicates that it is really good at finding TN instances, but at the cost of TP instances and similar for higher sensitivity.
# Therefore, it is not necessary that model with lowest OOB error wil have highest balanced accuracy,sensitivityand specificity.
```
